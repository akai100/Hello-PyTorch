## 默认 Stream

```python3
torch.cuda.default_stream()
```

+ 所有 CUDA op 默认 异步

+ Python 不阻塞

```python3
y = x + 1  # 不等 GPU
```

## 手动 stream

```python3
s = torch.cuda.Stream()
with torch.cuda.stream(s):
    y = x * 2
```

不同 stream 可并行执行（若无依赖）

## Event

```python3
start = torch.cuda.Event(enable_timing=True)
end = torch.cuda.Event(enable_timing=True)

start.record()
y = model(x)
end.record()

torch.cuda.synchronize()
print(start.elapsed_time(end), "ms")

```

## 显存管理

### CUDA Caching Allocator

PyTorch 使用 缓存分配器：

+ malloc → cache

+ free → cache

+ 减少 cudaMalloc 开销

```python3
torch.cuda.memory_allocated()
torch.cuda.memory_reserved()
```

### 手动释放

```python3
del tensor
torch.cuda.empty_cache()
```

不会还给 OS，只是清理 PyTorch cache

### OOM 调试

```python3
torch.cuda.memory_summary()
```

```python3
TORCH_CUDA_ALLOC_CONF=expandable_segments:True
```

### 显存碎片化

+ 典型原因

  + 动态 shape
 
  + 多模型交替运行
 
  + 临时 大 tensor

**解决：**

+ 固定 batch

+ ```torch.compile(dynamic=True)```

+ gradient checkpoint
